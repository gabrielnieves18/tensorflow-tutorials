{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call %matplotlib only in a Jupiter notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Common and local imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "This notebook contains the code to train and save the initial twenty convolutional layers that will be pre-trained for optimization purposes.\n",
    "\n",
    "The full model contains a total of twenty four convolutional layers. The initial twenty (what we create here) will be tasked on feature extraction and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reading inputs\n",
    "To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create synset to words map of all synsets currently \n",
    "# supported in ImageNet\n",
    "synset_to_word = dict([])\n",
    "\n",
    "words = open('words.txt','r')\n",
    "\n",
    "for line in words:\n",
    "    if line.strip():\n",
    "        line = line.rstrip().split(\"\\t\")\n",
    "        synsets_str = line[1]\n",
    "        synsets = [synsets_str]\n",
    "        if \",\" in synsets_str:\n",
    "            synsets = synsets_str.split(\",\")\n",
    "\n",
    "        synset_to_word[line[0]] = synsets\n",
    "\n",
    "words.close() # always close your files.\n",
    "\n",
    "\n",
    "# constants\n",
    "LAYER_TYPES = dict([\n",
    "    (\"conv\", \"convolutional\"),\n",
    "    (\"conn\", \"connected\"),\n",
    "    (\"det\", \"detection\"),\n",
    "    (\"drop\", \"dropout\"),\n",
    "    (\"local\", \"local\"),\n",
    "    (\"maxpool\", \"maxpool\")\n",
    "])\n",
    "\n",
    "classes = ['dogs', 'cats'] \n",
    "num_classes = len(classes)\n",
    "train_path='training_data'\n",
    "\n",
    "\n",
    "# Input values\n",
    "img_size = 448 # 448 x 448 RGB image\n",
    "num_channels = 3 # JPEG images have 3 channels (RGB)\n",
    "batch_size = 64 # batch size\n",
    "\n",
    "# Image configurations \n",
    "subdiv=7 # subdivisions for the image\n",
    "momentum=0.9\n",
    "decay=0.0005\n",
    "saturation=1.5\n",
    "exposure=1.5\n",
    "hue=.1\n",
    "\n",
    "# Learning Rate and Network graph params\n",
    "learning_rate=0.0005\n",
    "steps=200,400,600,20000,30000\n",
    "policy=steps\n",
    "scales=2.5,2,2,.1,.1\n",
    "max_batches = 40000\n",
    "\n",
    "# data = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-31-1789c8a238c0>, line 141)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-1789c8a238c0>\"\u001b[0;36m, line \u001b[0;32m141\u001b[0m\n\u001b[0;31m    elif LAYER_TYPES[\"det\"] in layer_type:\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def create_biases(size):\n",
    "    \"\"\"\n",
    "    To-Do\n",
    "    \"\"\"\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))\n",
    "\n",
    "def create_weights(shape, stddev=0.05):\n",
    "    \"\"\"\n",
    "    To-Do\n",
    "    \"\"\"\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=stddev))\n",
    "\n",
    "def create_flatten_layer(layer):\n",
    "    \"\"\"\n",
    "    To-Do\n",
    "    \"\"\"\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def create_fully_connected_layer(input,          \n",
    "                    num_inputs,    \n",
    "                    num_outputs,\n",
    "                    use_relu=True):\n",
    "    \"\"\"\n",
    "    To-Do\n",
    "    \"\"\"\n",
    "    #Let's define trainable weights and biases.\n",
    "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = create_biases(num_outputs)\n",
    " \n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    " \n",
    "    return layer\n",
    "\n",
    "def create_convolutional_layer(input,\n",
    "                               num_input_channels,\n",
    "                               conv_filter_size,\n",
    "                               num_filters, \n",
    "                               subdivisions, \n",
    "                               use_relu=True):\n",
    "    \"\"\"\n",
    "    This function facilitates the creation of a convolution layer for the YOLO algorithim.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        input (Tensor): the output (activation) from the previous layer. This should be a 4-D tensor. \n",
    "            Typically, in the first convolutional layer, you pass n images of size width * height * num_channels, \n",
    "            then this has the size [n width height num_channels].\n",
    "\n",
    "        num_input_channels (int): the number of imput channels for the image. JPG's have RGB channels, so it \n",
    "            would be 3 while PNG's have an extra channel called alpha (RGBA) so in this case it would be  4.\n",
    "        \n",
    "        conv_filter_size (int): Size that will be use for the width and height of the filter.\n",
    "        \n",
    "        num_filters (int): The number of filters that this layer will contain.\n",
    "        \n",
    "        subdivisions (int): The dimension for the image segmentation size. The number of grids per row in the image\n",
    "        \n",
    "        use_relu (bool): By default it's true. Whether to use relu before returning layer or not.\n",
    "        \n",
    "    Return:\n",
    "        Tensor: returns the activation function output if use_relu = True, otherwise, return the output of \n",
    "            the maxpooling output.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We shall define the weights that will be \n",
    "    # trained using create_weights function.\n",
    "    weights = create_weights(shape=[conv_filter_size, \n",
    "                                    conv_filter_size, \n",
    "                                    num_input_channels, \n",
    "                                    num_filters])\n",
    "    \n",
    "    # We create biases using the create_biases function. \n",
    "    # These are also trained.\n",
    "    biases = create_biases(num_filters)\n",
    "\n",
    "    # Creating the convolutional layer\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    layer += biases\n",
    "\n",
    "    # We shall be using max_pool (max pooling).  \n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "    \n",
    "    if(use_relu):    \n",
    "        # Output of pooling is fed to Relu which \n",
    "        # is the default activation function for us.\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def create_network(net_description = []):\n",
    "    \"\"\"\n",
    "    To-Do\n",
    "    \n",
    "    Example:\n",
    "        create_network([\n",
    "            net_description_item(batch_normalize=1,\n",
    "                filters=1024,\n",
    "                layer_type: LAYER_TYPES['conv'],\n",
    "                pad=1,\n",
    "                size=3,\n",
    "                stride=1,\n",
    "                activation=leaky),    \n",
    "            net_description_item(layer_type: LAYER_TYPES[\"maxpool\"],\n",
    "                size=2,\n",
    "                stride=2),\n",
    "            .\n",
    "            .\n",
    "            .\n",
    "            net_description_item(layer_type: LAYER_TYPES[\"conn\"],\n",
    "                output=1715\n",
    "                activation=linear),\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        net_description ( Array(Object) ): \n",
    "    \"\"\"\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        \n",
    "        input = tf.placeholder(tf.float32, \n",
    "                   shape=[None, img_size,img_size, num_channels], \n",
    "                   name='x')\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for layer in net_description:\n",
    "            \n",
    "            layer_type = layer[\"layer_type\"]\n",
    "            \n",
    "            if LAYER_TYPES[\"conv\"] in layer_type:\n",
    "                network.append(create_convolutional_layer(input,\n",
    "                                                     num_input_channels=num_channels,\n",
    "                                                     conv_filter_size=filter_size_conv1,\n",
    "                                                     num_filters=num_filters_conv1, \n",
    "                                                     subdivisions=subdiv, \n",
    "                                                     use_relu=False)\n",
    "                              )\n",
    "                input = network[-1]\n",
    "                \n",
    "            elif LAYER_TYPES[\"conn\"] in layer_type:\n",
    "    \n",
    "            elif LAYER_TYPES[\"det\"] in layer_type:\n",
    "\n",
    "            elif LAYER_TYPES[\"drop\"] in layer_type:\n",
    "\n",
    "            elif LAYER_TYPES[\"local\"] in layer_type:\n",
    "\n",
    "            else: # maxpool\n",
    "        \n",
    "    return network\n",
    "\n",
    "        \n",
    "def net_description_item(activation=\"leaky\", batch_normalize=1, classes=num_classes, coords=4, \n",
    "                         filters=1024, jitter=.2, layer_type='convolutional', num=3, output=1715, \n",
    "                         pad=1, probability=.5, rescore=1, softmax=0, sqrt=1, side=7, size=3, \n",
    "                         stride=1):\n",
    "    \"\"\"\n",
    "    To-Do\n",
    "    \n",
    "    Helper for the create_network function. Helps in creation of network \n",
    "    description dictionary items\n",
    "    \n",
    "    Args:\n",
    "        activation (str): ['leaky' | 'linear']\n",
    "    \"\"\"\n",
    "    net_item = dict([(\"layer_type\", layer_type)])\n",
    "    \n",
    "    if LAYER_TYPES[\"conv\"] in layer_type:\n",
    "        net_item[\"activation\"] = activation\n",
    "        net_item[\"batch_normalize\"] = batch_normalize\n",
    "        net_item[\"filters\"] = filters\n",
    "        net_item[\"size\"] = size\n",
    "        net_item[\"stride\"] = stride\n",
    "        net_item[\"pad\"] = pad\n",
    "        \n",
    "    elif LAYER_TYPES[\"conn\"] in layer_type:\n",
    "        net_item[\"activation\"] = activation\n",
    "        net_item[\"output\"] = output\n",
    "    \n",
    "    elif LAYER_TYPES[\"det\"] in layer_type:\n",
    "        net_item[\"classes\"] = classes\n",
    "        net_item[\"coords\"] = coords\n",
    "        net_item[\"rescore\"] = rescore\n",
    "        net_item[\"size\"] = size\n",
    "        net_item[\"num\"] = num\n",
    "        net_item[\"softmax\"] = softmax\n",
    "        net_item[\"sqrt\"] = sqrt\n",
    "        net_item[\"jitter\"] = jitter\n",
    "        \n",
    "    elif LAYER_TYPES[\"drop\"] in layer_type:\n",
    "        net_item[\"probability\"] = probability\n",
    "        \n",
    "    elif LAYER_TYPES[\"local\"] in layer_type:\n",
    "        net_item[\"activation\"] = activation\n",
    "        net_item[\"filters\"] = filters\n",
    "        net_item[\"size\"] = size\n",
    "        net_item[\"stride\"] = stride\n",
    "        net_item[\"pad\"] = pad\n",
    "    \n",
    "    else: # maxpool\n",
    "        net_item[\"size\"] = size\n",
    "        net_item[\"stride\"] = stride\n",
    "        \n",
    "    return net_item\n",
    "\n",
    "\n",
    "def train(num_iteration):\n",
    "    \"\"\"\n",
    "    To-Do\n",
    "    \"\"\"\n",
    "    total_iterations = 0\n",
    "    loss = []\n",
    "    epochs = []\n",
    "    accuracy_array = []\n",
    "    \n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:   \n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(total_iterations,\n",
    "                       total_iterations + num_iteration):\n",
    "\n",
    "            x_batch, y_true_batch, _, cls_batch = data.train.next_batch(batch_size)\n",
    "            x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(batch_size)\n",
    "            \n",
    "            feed_dict_tr = {\n",
    "                x: x_batch, \n",
    "                y_true: y_true_batch\n",
    "            }\n",
    "        \n",
    "            feed_dict_val = {\n",
    "                x: x_valid_batch,\n",
    "                y_true: y_valid_batch\n",
    "            }\n",
    "\n",
    "            session.run(optimizer, feed_dict=feed_dict_tr)\n",
    "\n",
    "            if i % int(data.train.num_examples/batch_size) == 0: \n",
    "                val_loss = session.run(cost, feed_dict=feed_dict_val)\n",
    "                epoch = int(i / int(data.train.num_examples/batch_size))    \n",
    "\n",
    "                loss.append(val_loss)\n",
    "                epochs.append(epoch)\n",
    "                accuracy_array.append(session.run(accuracy, feed_dict=feed_dict_tr))\n",
    "                \n",
    "                loss_map = {\n",
    "                    'loss': loss,\n",
    "                    'epochs': epochs,\n",
    "                    'accu': accuracy_array \n",
    "                }\n",
    "\n",
    "#                 if (epoch > 0) and (epoch % 5) == 0:\n",
    "#                     pd_loss = pd.DataFrame(loss_map)\n",
    "#                     pd_loss.plot(x=\"accu\", y=\"loss\", kind='line')\n",
    "#                     plt.show()  \n",
    "                \n",
    "                show_progress(epoch, \n",
    "                              feed_dict_tr, \n",
    "                              feed_dict_val,\n",
    "                              val_loss,\n",
    "                              session)\n",
    "\n",
    "                saver.save(session, './dogs-cats-model') \n",
    "                \n",
    "        total_iterations += num_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
